# 正则规则模型（regex_rule.py）
## 优缺点分析
### 优点
推理效率极致：无特征计算、模型训练等中间过程，仅执行文本匹配逻辑，毫秒级完成意图判定，硬件资源消耗几乎可忽略，能支撑超高并发场景。
逻辑完全可解释：意图判定的依据是明确的人工规则（如 “包含‘退款’+16 位数字订单号”），出现误判时可直接定位到具体规则条目，排查和修复成本极低。
零训练与标注成本：无需标注样本、无需算力投入，仅需开发人员编写规则即可上线，冷启动周期极短（小时级）。
结果边界可控：可精准限定意图判定范围，完全规避非预期的泛化结果，适合金融、合规等高确定性要求的场景。
### 缺点
泛化能力极弱：仅能匹配预定义规则的文本范式，无法处理口语化、变体表达（如规则匹配 “查询订单 + 数字”，但无法识别 “想瞅瞅我的订单到哪了” 这类口语表述），也无法适配用户表达习惯的变化。
规则维护成本指数级增长：新增意图需同步编写新规则，意图数量超过 50 个后，规则体系易出现冲突（如 “查物流” 和 “查订单” 规则重叠）、冗余问题，冲突排查和规则迭代耗时耗力。
无法处理语义模糊场景：对于无固定文本模式的意图（如 “对商品不满意”“想咨询售后政策”），无法通过规则精准判定，易出现大量漏判或误判。
多语言 / 方言适配性差：规则高度依赖特定语言的字符、句式结构，适配方言（如粤语）或小语种时，需重新编写全套规则，适配成本极高。
# TF-IDF + 传统机器学习模型（tfidf_ml.py）
## 优缺点分析
### 优点
工程落地成本低：TF-IDF 特征提取和传统机器学习算法均有成熟开源库（如 sklearn）支持，无需深度学习框架，开发、部署门槛低，普通研发人员即可完成。
训练与推理效率均衡：训练速度远快于深度学习模型，百级 / 千级标注样本即可快速收敛；推理阶段仅需完成特征计算和简单分类逻辑，普通 CPU 即可支撑万级 QPS。
可解释性优于深度学习：可通过特征权重（如某关键词的 TF-IDF 值、模型特征系数）分析模型判定意图的依据，便于业务侧理解和调优。
对数据量要求低：在百级标注样本下即可达到 60%-80% 的分类准确率，无需大规模标注数据，适合数据稀缺的冷启动阶段。
### 缺点
语义理解能力缺失：仅依赖关键词的词频特征，无法捕捉上下文语义关联（如 “苹果手机退款” 和 “苹果水果退款” 无法区分），也无法处理一词多义、语义变体问题。
对文本预处理高度依赖：停用词过滤、分词错误、特殊字符未清洗等问题，会直接导致特征质量下降，进而使分类准确率大幅降低，预处理环节的疏漏难以规避。
稀疏特征效率瓶颈：TF-IDF 生成的稀疏矩阵维度随词汇量线性增长，存储和计算成本上升明显，且易出现 “维度灾难”，导致模型收敛速度变慢、泛化能力下降。
跨场景迁移能力弱：跨领域（如从 “电商订单” 迁移到 “外卖订单”）或跨表达范式时，需重新标注数据并训练模型，适配成本接近重新开发。
# BERT 预训练模型（bert.py）
## 优缺点分析
### 优点
深度语义理解能力：能精准捕捉上下文依赖和语义关联，可区分一词多义、同义不同形的表达（如 “查物流” 和 “看看我的订单到哪了”），分类准确率通常可达 90% 以上，远超规则和传统机器学习。
迁移学习能力强：复用通用领域的预训练权重，仅需少量（千级）领域内标注数据微调即可适配业务场景，大幅降低标注成本。
泛化能力优异：跨句式、跨表达风格、轻度跨领域场景下仍能保持稳定效果，无需频繁调整模型参数。
可扩展性强：可通过接入领域预训练权重、增加微调数据、优化分类头结构、融合知识图谱等方式持续提升效果，适配复杂业务需求。
### 缺点
算力与部署成本高：训练 / 微调需 GPU（如 NVIDIA T4/A10）支撑，单轮微调耗时数小时；推理阶段单条请求耗时约 10-50ms（CPU 环境），高并发场景需部署 GPU 集群或做模型压缩（量化 / 蒸馏），硬件和运维成本显著上升。
模型可解释性差：基于深度神经网络的 “黑盒” 特性，无法直观解释模型判定意图的依据，出现误判时难以定位根因（如无法确定是某关键词还是语义关联导致误判）。
对标注数据质量要求高：虽需数据量少于纯从头训练的深度学习模型，但仍需千级以上高质量标注样本，噪声数据（如标注错误、样本重复）易导致模型过拟合，泛化能力下降。
冷启动周期长：从数据标注、模型微调、效果验证到上线，周期通常在数天至数周，不适合需快速上线的业务场景。
# Prompt 提示词模型（prompt.py）
## 优缺点分析
### 优点
低资源适配能力突出：零样本 / 少样本（数十 / 数百条标注）场景下仍能达到 70%-85% 的分类准确率，大幅降低标注数据依赖，适合冷启动或小众意图分类场景。
复用预训练能力：无需对模型做大规模微调，仅通过设计提示词模板引导预训练模型输出结果，算力消耗仅为 BERT 全量微调的 10%-20%。
灵活适配性：无需修改模型结构，仅调整提示词模板即可适配新意图 / 新场景，迭代效率远高于重新微调 BERT 模型（小时级完成适配）。
语义理解保留：继承预训练模型的深度语义理解能力，在小样本下仍能捕捉文本核心语义，效果显著优于同数据量下的 BERT 微调。
### 缺点
模板设计高度依赖经验：提示词模板的句式、关键词、答案格式直接决定模型效果，需大量实验调试（通常需测试数十种模板），且不同场景的最优模板差异大，适配成本高。
推理结果稳定性差：生成式输出易出现模糊、偏离预期的答案（如意图判定结果不唯一、出现无关文本），需额外增加后处理逻辑（如答案归一化、阈值过滤），增加工程复杂度。
推理速度略慢于普通 BERT：需引导模型完成生成任务，推理链路比直接分类更长，单条请求耗时比普通 BERT 增加 10%-30%。
大规模样本下效果逊于 BERT 微调：当标注数据充足（千级以上）时，Prompt 模型的分类准确率通常比全量微调的 BERT 低 5%-10%，无法充分利用标注数据的价值。