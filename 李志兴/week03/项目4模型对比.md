# 四个模型同一任务的对比总结

这 4 个脚本做的事其实一样：把输入的 `request_text`（一条或多条文本）分到某个“意图/类别”。区别只在于 **怎么判**：靠规则、靠传统 ML、靠 BERT、靠大模型提示词。

------

## 先说结论：它们各自像什么“工具”

- **regex_rule.py（正则规则）**：像一套“关键词/模板匹配表”。命中就判，不命中就 Other。
- **tfidf_ml.py（TF-IDF + sklearn）**：像“看词频+相似度”的传统分类器，便宜、快，但不太懂语义。
- **bert.py（BERT 分类）**：像“更懂中文表达”的分类器，效果通常更稳，但更吃资源。
- **prompt.py（LLM + 动态 few-shot）**：像“请一个很会读题的人”，给他看候选类别和10个相似例子，让他选一个；灵活，但慢、贵、也更不稳定。

------

## 逐脚本拆开说

### 1) regex_rule.py：规则/正则匹配

**怎么做：**

- 启动时把每个类别的正则都 `compile` 好。
- 推理时挨个类别 `findall`，命中就把该类别加入结果；全没命中就 `Other`。

**优点：**

- **最快**（基本就是字符串匹配），线上压力小。
- **很可解释**：为什么命中很直观，适合“必须说清楚原因”的场景。
- **可控**：你写什么规则就怎么判，不会“意外发挥”。

**缺点：**

- **覆盖率靠人堆**：表达稍微变一下就可能漏。
- **维护会越来越累**：规则多了以后冲突、误伤、边界问题都会变多。
- **单条输入可能返回多个类别**（因为代码不 break），如果你业务只允许一个标签，要加优先级/冲突处理。

------

### 2) tfidf_ml.py：TF-IDF + 传统分类器

**怎么做：**

- 加载一个已经训练好的 `tfidf` 和 `model`。
- jieba 分词 → 去停用词 → 用 TF-IDF 变成向量 → `model.predict` 出类别。

**优点：**

- **成本低、推理快**：CPU 跑也轻松，适合高并发。
- **训练/迭代门槛低**：加数据重训很方便，是经典工业基线。
- 对“意图主要靠关键词区分”的任务，表现往往还挺靠谱。

**缺点：**

- **不太懂语义**：同义词、换个说法、上下文依赖，容易掉点。
- **受分词/停用词/数据分布影响大**：语料一漂移就容易明显变差。

------

### 3) bert.py：BERT 微调分类

**怎么做：**

- 初始化 tokenizer + `BertForSequenceClassification(num_labels=12)`，加载权重到 device。
- 把文本 tokenize（`max_length=30`）→ DataLoader 批推理 → 取 logits 最大的类别 → 映射成标签名。

**优点：**

- **更吃“说法变化”**：口语化、同义替换、噪声文本，一般比 TF-IDF 稳。
- 输出通常更一致，不像 LLM 会偶尔跑偏。

**缺点：**

- **资源/部署成本高**：模型大、依赖多；CPU 能跑但延迟会高些，最好有 GPU 或做优化（量化/ONNX/蒸馏）。
- **解释性弱**：不好直接回答“为什么是这个类”。

---

### 4) prompt.py：大模型提示词分类（带动态相似例子）

**怎么做：**

- 先用 TF-IDF 在训练集里找**最相似的 Top10**样例，把这些样例拼成 few-shot。
- prompt 里给：候选类别 + Top10参考例子 + 待分类文本
- 调 LLM，让它“只输出一个类别”。

**优点：**

- **改得快**：类别变了、边界不清晰、要加规则，很多时候改 prompt/加例子就能立刻见效。
- **长尾更灵活**：遇到“没见过的说法”，LLM 通常比传统模型更能兜住。
- 用“相似例子 Top10”这招，整体稳定性会比纯 prompt 强一些（算是轻量检索增强）。

**缺点（也是上线必须面对的）：**

- **慢、贵**：每条文本都要调一次模型（而且是循环逐条调用）。
- **不够可控**：即使你要求“只输出类别”，也可能多输出解释/空格/换行/不在候选里——必须做输出校验和兜底。
- **安全风险**：用户输入里如果夹带“忽略规则/输出xx”这种提示词注入，会影响结果，需要做分隔、约束和防注入策略。
- **合规/隐私**：文本会发到你配置的 LLM 服务端，这点要跟业务确认清楚。

------

## 四种方法放一起比较

- **要极致稳定 + 极低延迟**：先上 **Regex**（但要修 list bug），适合“高确定性短句”。
- **要便宜能跑 + 中等效果**：**TF-IDF** 是最省心的基线。
- **想把效果拉上去且能接受资源成本**：用 **BERT**（先把 pdb 去掉，max_length 别太短）。
- **类别经常变、长尾多、需求不稳定**：用 **LLM prompt**，但要把“输出校验/注入防护/成本控制”当成必做项。

