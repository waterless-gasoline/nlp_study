1.需要使用数据库，因为类别挺多的，使用数据库方便管理
对于功能1，需要类目表，结构为类别名称、级别、faq信息
对于功能2，需要faq知识表，faq信息问题、待选提问、相似提问、生效时间、答案
2.选择使用预训练模型bert较好，因为bert的预训练让模型对文本已经具备了一定的理解能力，更有利于我们完成nlp任务
3.根据四大基本任务可以知道，可将bert应用于文本分类、文本匹配、序列标注三个方向，具体的bert使用可以使用tokenizer读取相应的bert预训练权重，
后续使用过程对于序列标注任务需要注意的就是bert模型的标注和正常标注不一样，可能会把几个数字当成一个整体，一个中文拆开就会导致输入输出不匹配，
影响训练效果此时可以使用BertTokenizer解决这个问题
4.对于这个任务还无需使用大模型，因为这个任务可以结合文本分类、文本匹配、序列标注解决还无需用到大模型，使用大模型首先的就是成本问题，本地训练无需成本；接着
就是响应速度的问题，对于这个系统响应速度尤为重要，使用大模型很大的缺点就是反应速度慢，而本地训练的模型就不一样，响应速度远快于大模型；还有一个很重要的点就是大模型
的幻觉问题会影响系统的准确率，而本地训练模型可以更有利于解决这个问题
