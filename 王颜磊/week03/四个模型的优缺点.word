| 模型 | 优点 | 缺点 |
|------|------|------|
| 正则表达式（Regex） | - 精确可控，结果可预测<br>- 无需训练，零成本部署<br>- 执行效率高，资源占用极低<br>- 完全可解释，调试直观 | - 泛化能力差，无法处理未定义变体<br>- 维护复杂，规则难以扩展<br>- 无语义理解能力<br>- 对多语言、口语化文本支持弱 |
| TF-IDF | - 实现简单，计算高效<br>- 无需标注数据（无监督）<br>- 特征可解释（每个维度对应一个词）<br>- 内存友好（稀疏向量） | - 忽略词序、语法和上下文<br>- 无法捕捉语义相似性（如“汽车”≠“轿车”）<br>- 高维稀疏，易受噪声干扰<br>- 对短文本或小样本效果差 |
| BERT | - 深度上下文语义理解（一词多义）<br>- 双向建模，信息利用充分<br>- 迁移学习能力强，微调即可适配多种任务<br>- 支持分类、NER、问答等判别式任务 | - 计算资源消耗大（需 GPU）<br>- 黑盒模型，决策难解释<br>- 输入长度受限（通常 ≤512 tokens）<br>- 微调需标注数据，小数据易过拟合 |
| GPT-4 | - 强大生成与推理能力<br>- 零样本/少样本学习，无需微调<br>- 支持长上下文（最高 128K tokens）<br>- 多轮对话、多语言、多模态（部分版本） | - 闭源且 API 调用成本高<br>- 存在“幻觉”，可能编造事实<br>- 响应延迟较高，不适合实时系统<br>- 数据隐私风险，不可本地部署（官方版） |
