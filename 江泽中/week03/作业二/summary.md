# 文本处理方法优缺点对比

## BERT（预训练语言模型）
**优点** ✅
- 语境理解能力强，处理一词多义效果好
- 预训练模型通用性强，可适应多种任务
- 在大多数NLP任务中表现SOTA

**缺点** ❌
- 计算资源要求高，推理速度慢
- 需要大量标注数据微调
- 模型参数量大，部署成本高

## Prompt（提示学习）
**优点** ✅
- 小样本/零样本场景表现好
- 减少对大规模标注数据的依赖
- 统一多种任务的范式

**缺点** ❌
- 提示设计需要人工经验
- 效果对提示模板敏感
- 推理成本仍较高

## Regex Rule（正则规则）
**优点** ✅
- 规则完全可控，可解释性强
- 处理速度快，资源消耗低
- 适用于模式明确的结构化文本

**缺点** ❌
- 无法处理复杂语义
- 规则维护成本高
- 泛化能力差，模式一变就失效

## TF-IDF + ML（传统机器学习）
**优点** ✅
- 训练和推理速度快
- 可解释性相对较好
- 小数据量下也能工作

**缺点** ❌
- 无法捕捉语义和上下文
- 特征工程依赖人工经验
- 处理复杂任务效果有限

---

**简单总结：**
- 追求效果选 **BERT**
- 少样本场景试 **Prompt**  
- 规则明确用 **Regex**
- 轻量快速用 **TF-IDF+ML**