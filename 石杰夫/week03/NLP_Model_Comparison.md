## 1. 正则规则模型 (Regex / Rule-based)

基于人工定义的关键词和正则表达式模式进行匹配。

### ✅ 优点
*   **无需训练数据**：不需要标注数据，冷启动极快，写好规则即可上线。
*   **极高的精确率 (Precision)**：对于特定模式（如电话号码、身份证、固定指令），可以做到几乎 100% 正确。
*   **完全可解释**：匹配原因一目了然，便于 Debug。
*   **性能极高**：计算量极小，CPU 即可处理海量数据。

### ❌ 缺点
*   **召回率低 (Recall)**：泛化能力极差，无法处理用户表达的多样性（如错别字、同义词）。
*   **维护成本高**：随着业务复杂度增加，规则库会变得极其庞大且难以维护，容易产生规则冲突。
*   **无语义理解**：无法理解上下文，仅是字符匹配。

---

## 2. TF-IDF + 传统机器学习 (Traditional ML)

使用 TF-IDF 或 N-gram 提取文本特征，配合朴素贝叶斯 (Naive Bayes)、逻辑回归 (LR) 或 SVM 进行分类。

### ✅ 优点
*   **训练与推理速度快**：相比深度学习，计算开销非常小。
*   **数据需求适中**：在中小规模数据集上往往能取得不错的 Baseline 效果。
*   **特征有一定的可解释性**：可以通过权重查看哪些词对分类贡献最大。

### ❌ 缺点
*   **忽略语序和语义**：基于“词袋模型”(Bag of Words)，无法区分“狗咬人”和“人咬狗”，也无法理解“苹果”是水果还是手机（一词多义）。
*   **数据稀疏**：TF-IDF 矩阵通常非常稀疏，维度灾难问题明显。
*   **OOV 问题**：难以处理训练集中未出现的词（未登录词）。

---

## 3. BERT 预训练模型 (Pre-trained Language Models)

基于 Transformer 架构的深度学习模型，通过在大规模语料上预训练 + 下游任务微调 (Fine-tuning)。

### ✅ 优点
*   **强大的语义理解**：双向上下文编码，能完美解决一词多义、指代消歧等复杂语义问题。
*   **SOTA 效果**：在绝大多数 NLP 任务（分类、实体抽取等）上，准确率远超传统模型。
*   **迁移学习能力**：只需少量标注数据进行微调，即可获得很好的效果。

### ❌ 缺点
*   **硬件资源要求高**：训练和推理通常需要 GPU 支持，部署成本高。
*   **速度较慢**：推理延迟显著高于规则和传统 ML。
*   **黑盒模型**：可解释性较差，难以直观理解模型决策依据。

---

## 4. Prompt 提示词模型 (LLM / Large Language Models)

使用 GPT-3.5/4, Qwen, Claude 等大语言模型，通过设计 Prompt (提示词) 直接完成任务。

### ✅ 优点
*   **零样本/少样本能力 (Zero-shot/Few-shot)**：往往不需要任何训练数据，或者仅需几个示例即可处理任务。
*   **通用性强**：一个模型可以处理分类、摘要、翻译、改写等多种任务。
*   **开发效率极高**：无需通过代码构建模型架构，无需训练过程，直接通过自然语言交互。

### ❌ 缺点
*   **推理成本昂贵**：API 调用费用高，或本地部署显存要求极高。
*   **高延迟**：生成式模型的响应速度通常较慢，不适合对实时性要求极高的场景。
*   **不可控性 (幻觉)**：可能一本正经地胡说八道，输出格式有时不稳定，难以做到 100% 的指令遵循。
*   **数据隐私**：使用公有云 API 可能涉及数据出境或隐私泄露风险。

---

## 总结对比表

| 维度 | 正则规则 | TF-IDF + 传统 ML | BERT 微调 | Prompt (LLM) |
| :--- | :--- | :--- | :--- | :--- |
| **语义理解** | 无 | 弱 (仅词频) | 强 | 极强 |
| **训练数据** | 不需要 | 需要 | 需要 (少量至中量) | 不需要/极少 |
| **推理速度** | 极快 | 快 | 慢 | 极慢 |
| **算力成本** | 极低 | 低 | 高 (GPU) | 极高 |
| **泛化能力** | 差 | 一般 | 好 | 极好 |
| **可解释性** | 强 | 中 | 弱 | 弱 (但可追问) |
| **适用场景** | 强规则、冷启动 | 简单分类、速度敏感 | 高精度、复杂语义 | 复杂生成、创意、多任务 |
